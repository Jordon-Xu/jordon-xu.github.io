<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jordon-Xu&#39;s Blog</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-10-02T03:20:22.203Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Jordon_Xu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Automatic Driving Experiment Platform Based on Machine Vision</title>
    <link href="http://example.com/2021/10/02/Automatic-Driving-Experiment-Platform-Based-on-Machine-Vision/"/>
    <id>http://example.com/2021/10/02/Automatic-Driving-Experiment-Platform-Based-on-Machine-Vision/</id>
    <published>2021-10-02T03:10:12.000Z</published>
    <updated>2021-10-02T03:20:22.203Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>The iteration of the automobile industry constantly promotes the rapid development of human economy and society. However, traffic jams and traffic accidents and other problems often cause trouble to People’s Daily travel. Therefore, more and more automobile manufacturers and technology companies begin to develop autonomous driving technology. Promoting autonomous driving cars has become the core development direction of the automobile industry.</p><p>First, this paper describes the process of building an autonomous driving experiment platform, as well as the software and hardware of the project, and the core design ideas and algorithms. Based on the chassis of the toy car, by using 3D model software to design the structure of the car, followed by printing out each part for assembly by 3D printer. The car contains on-board computer, suspension, differential, lighting, camera, distance sensor, and so on, having a high degree of hardware integration. At the same time, the car can be arbitrarily replaced or expanded through the modular idea. The road is simulated by grey foam panels, which can also be quickly built indoors and only covers an area of one square metre when storing.</p><p>Secondly, this paper introduces the idea of object - oriented design. Designing an event-driven real-time framework, and adopts the current mainstream machine vision and distance sensor method. In this paper, a new algorithm called “dynamic mask” is proposed to filter out non-pavement interference and predict the position of lane line.</p><p>Finally, this paper gives the autonomous driving state of the car in various typical road conditions, including keeping the middle of the lane, braking when encountering obstacles and passing through the intersection according to the traffic lights. Experimental results show that the proposed the autonomous driving platform based on machine vision is correct to a certain extent.</p><p>Key word: automatically driving, lane line detection, machine vision, real-time system, neural network</p><h1 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1 Introduction"></a>Chapter 1 Introduction</h1><h2 id="1-1-Project-Background"><a href="#1-1-Project-Background" class="headerlink" title="1.1 Project Background"></a>1.1 Project Background</h2><p>With the rapid development of science and technology, unmanned driving technology has attracted extensive attention of many scholars and related technology researchers. Legal and development costs make it important to have a small, suitable platform for autonomous driving. In computer-related courses, the author has developed a strong interest in the technical field of artificial intelligence and unmanned driving. Computer engineering has been determined as the future major direction, and the study will involve automation control, machine learning, software engineering and other fields. Therefore, an autonomous driving experimental platform for sustainable research has been designed. In my long study life in the future, new knowledge, new algorithms and new ideas in these fields can be fully practiced and verified on this platform. At the same time, we also hope that the platform design can provide a reference solution for readers.</p><h2 id="1-2-Development-status-of-autonomous-driving-technology"><a href="#1-2-Development-status-of-autonomous-driving-technology" class="headerlink" title="1.2 Development status of autonomous driving technology"></a>1.2 Development status of autonomous driving technology</h2><p>Some developed countries began the research of driverless vehicles at the end of the 20th century. In the 1980s, famous Universities in the United States, such as MIT and Carnegie Mellon University, started research on driverless vehicles. However, due to technical limitations, the project was gradually transformed into the assisted driving of civilian vehicles. In 1995, Navlab2 V, a driverless car developed by Carnegie Mellon University, was tested on a 5,000km interstate highway in the United States. Although the vehicle in the test only completed autonomous direction control, without speed control, it marked the basic success of the self-driving project. At the beginning of the 21st century, Toyota, Volkswagen and other companies have made achievements in assisted driving systems. In 2011, Google became the first company in the world to obtain the authorization of self-driving cars after Nevada passed the law on self-driving cars on roads [1]. In 2014, Tesla introduced its first generation of Autopilot, the equivalent of L2 level of autonomous driving; In 2021, Tesla officially released the Full self-driving system (FSD), which abandoned the millimeter wave radar and adopted the automatic Driving algorithm of pure vision, and reached the L4 level of automatic Driving.<br>China’s research on driverless vehicles is later than foreign countries. In 1992, the National University of Defense Technology successfully developed China’s first truly driverless car. In 2007, National University of Defense Technology and FAW Jointly developed Hongqi flagship driverless car [2], whose technology has reached the world’s advanced level. Companies such as BYD, Changan and Baidu have made good progress in driverless research and development in recent years, launching their own assisted driving technology that has scored as well as Tesla in unofficial tests.</p><h2 id="1-3-Breakthroughs-and-accumulation-of-artificial-intelligence-technology"><a href="#1-3-Breakthroughs-and-accumulation-of-artificial-intelligence-technology" class="headerlink" title="1.3 Breakthroughs and accumulation of artificial intelligence technology"></a>1.3 Breakthroughs and accumulation of artificial intelligence technology</h2><p>In August 1956, a number of scientists are gathered to discuss at the time can be considered to be one of the more advanced problem: use the machine to mimic human learning and other aspects of intelligence, although the discussion was not the result, but the birth of the concept of “artificial intelligence” and therefore, in the next half century, the development of artificial intelligence winding [3]. Until now, artificial intelligence technology represented by deep neural network has developed rapidly with the promotion of hardware/computing power, data and algorithm. Deep neural network has crossed the “technology gap” between science and application [4], bringing the development climax to technologies such as unmanned driving and image recognition. So now, as a high school student, I can also stand on the shoulders of giants to enter the FIELD of AI. I can build experimental platforms and complete engineering practices at home or in the primary laboratory at school.<br>The floating point computing power of graphics cards is the hardware foundation for the development of ARTIFICIAL intelligence. NVIDIA’s CUDA architecture provides support for deep learning computing power, which also promotes the development of autonomous driving technology. Before 2012, it was not common for people to use GPU for machine learning. Since 2012, AI computing power has increased by more than 300,000 times, and 10-100 Gpus with the speed of 5-10 TFLOPS are commonly used for large-scale model training. According to OpenAI, human computing needs double every 3.43 months, increasing by about 10 times per year [5]. In 2021, THE growth of GPU computing power will be similar to that of PC devices in the early years, and ordinary teams will be able to use GPU computing power to carry out complex machine learning projects. For example, the JETSON NANO used in this project has the computational power of 472 GFLOPs, but the volume is only 80x100mm, and the cost is only 800 yuan. This cost-effective hardware can only be obtained recently.<br>After 30 years of development, autonomous driving has accumulated a large amount of historical data, such as KITTI dataset, Audi open source autonomous driving Dataset (2020), Waymo open source autonomous driving dataset (Google autonomous driving department) [7], etc.<br>Until 2000, deep networks (more than ten layers) were not trained in a more reliable way, but this changed during 2009-2016, when several simple but important algorithm improvements were made to optimize the gradient propagation process of neural networks. In ILSVRC (ImageNet Large Scale Visual Recognition Challenge) competition, the best result of image classification was 26% error rate before 2012, but AlexNet reduced the error rate to 16% in 2012. The target positioning project increased its error rate to 9% in ResNet in 2015 from 25%, the previous year’s best score. Classical neural networks include AlexNet, VGG, ResNet, GoogleNet, YOLO[8], etc.</p><h2 id="1-4-Objective-and-significance-of-the-Project"><a href="#1-4-Objective-and-significance-of-the-Project" class="headerlink" title="1.4 Objective and significance of the Project"></a>1.4 Objective and significance of the Project</h2><p>The goal of this project is to build an automatic driving experiment platform, which consists of three parts:<br>(1) Freely built simulated road sites and traffic signs;<br>(2) Modular model car;<br>(3) Software framework of sustainable iterative optimization.<br>The significance of this project is as follows:<br>(1) Realize the modularization of software and hardware (sustainable optimization iteration) : use 3D printing to realize the modularization of on-board computer, actuator drive board, camera, sensor and connector, which can easily expand and replace different hardware modules; Based on the object-oriented program framework, with maintainability, scalability, in addition to sustainable optimization iteration of different core control algorithms.<br>(2) Low cost: The combination of ready-made toy parts and self-made 3D printed parts, as well as highly integrated electronic devices, can control the hardware cost of the project within a relatively low range.<br>(3) Small size: by maximizing the volume of the car, the simulated site area is reduced, and portable and fast construction is realized, which is very suitable for students.<br>(4) Compared with the simulation system, there are more opportunities for hardware practice: the design of the car involves the basic mechanical principles of the vehicle – driving form (front drive, rear drive, four-wheel drive), the role and form of suspension, the role of differential, the steering ackerman geometry principle, etc. At the same time, electromagnetic compatibility of electronic components should also be considered - the design needs to consider the adaptation of different control board operating voltage, system power demand, endurance, voltage regulator power supply (waveform), power supply electromagnetic interference, etc.</p><h1 id="Chapter-2-Automatic-driving-experiment-platform-construction"><a href="#Chapter-2-Automatic-driving-experiment-platform-construction" class="headerlink" title="Chapter 2 Automatic driving experiment platform construction"></a>Chapter 2 Automatic driving experiment platform construction</h1><h2 id="2-1-Modular-design-of-model-car"><a href="#2-1-Modular-design-of-model-car" class="headerlink" title="2.1 Modular design of model car"></a>2.1 Modular design of model car</h2><h3 id="2-1-1-Trolley-chassis"><a href="#2-1-1-Trolley-chassis" class="headerlink" title="2.1.1 Trolley chassis"></a>2.1.1 Trolley chassis</h3><p>Choose a model car online shopping, using its chassis for transformation. The car is four-wheel independent double fork arm suspension, driving form is rear drive (can be upgraded to four-wheel drive), replaced by dc motor drive with encoder; The original steering gear drive is retained, and the steering mechanism conforms to Ackerman steering geometry (a geometry that addresses the different centers of the vehicle’s inner and outer steering wheel paths when turning).<br>Closed-loop control of vehicle speed and travel distance is carried out. Speed is measured by Hall encoder – mechanical geometric displacement on the output shaft is converted into pulse or digital quantity through magnetoelectric conversion, and direction is judged by two groups of square wave signals with phase difference [9], as shown in FIG. 2.1. The actual speed of the motor is fed back to the input to form a control closed loop.<br><img src="http://m.qpic.cn/psc?/V52O6T4v1BaKX82y9mu62U2PpX2MjRTM/45NBuzDIW489QBoVep5mccUgWovqVSuX3wqpL0*EHUYr9lYLczxSMVvksLTGc4JFPpPMpUiRkaLEJua*JMY1srIsPpn8U8vIeCxR9CPCwqc!/b&bo=*gFAAf4BQAEBGT4!&rf=viewer_4" alt="Figure 2.1"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;The iteration of the automobile industry const</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Autonomous driving experimental prototype (Video)</title>
    <link href="http://example.com/2021/10/01/Autonomous-driving-experimental-prototype/"/>
    <id>http://example.com/2021/10/01/Autonomous-driving-experimental-prototype/</id>
    <published>2021-10-01T15:33:50.000Z</published>
    <updated>2021-10-02T03:01:37.635Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Achievement"><a href="#Achievement" class="headerlink" title="Achievement"></a>Achievement</h1><h2 id="YouTube"><a href="#YouTube" class="headerlink" title="YouTube"></a>YouTube</h2><iframe width="800" height="600" src="https://www.youtube.com/embed/rnZj9ERG7J8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><h2 id="Bilibili"><a href="#Bilibili" class="headerlink" title="Bilibili"></a>Bilibili</h2><iframe src="//player.bilibili.com/player.html?aid=890260479&bvid=BV1pP4y1a7Lm&cid=403883060&page=1" width="800px" height="600px" border="0" frameborder="yes" framespacing="0" allowfullscreen="true"> </iframe>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Achievement&quot;&gt;&lt;a href=&quot;#Achievement&quot; class=&quot;headerlink&quot; title=&quot;Achievement&quot;&gt;&lt;/a&gt;Achievement&lt;/h1&gt;&lt;h2 id=&quot;YouTube&quot;&gt;&lt;a href=&quot;#YouTube&quot; c</summary>
      
    
    
    
    <category term="FSD" scheme="http://example.com/categories/FSD/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="FSD" scheme="http://example.com/tags/FSD/"/>
    
    <category term="machine vision" scheme="http://example.com/tags/machine-vision/"/>
    
  </entry>
  
  <entry>
    <title>无人驾驶小车项目（FSD）（测试）</title>
    <link href="http://example.com/2021/02/07/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E5%B0%8F%E8%BD%A6%E9%A1%B9%E7%9B%AE%EF%BC%88FSD%EF%BC%89%EF%BC%88%E6%B5%8B%E8%AF%95%EF%BC%89/"/>
    <id>http://example.com/2021/02/07/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E5%B0%8F%E8%BD%A6%E9%A1%B9%E7%9B%AE%EF%BC%88FSD%EF%BC%89%EF%BC%88%E6%B5%8B%E8%AF%95%EF%BC%89/</id>
    <published>2021-02-07T01:41:40.000Z</published>
    <updated>2021-10-01T12:15:43.156Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>to simulate FSD of Tesla at home</p><h2 id="Build-the-car"><a href="#Build-the-car" class="headerlink" title="Build the car"></a>Build the car</h2><h4 id="3D-modeling-and-3D-printing"><a href="#3D-modeling-and-3D-printing" class="headerlink" title="3D modeling and 3D printing"></a>3D modeling and 3D printing</h4><h4 id="core-of-NVIDIA™-JETSON-NANO™-development-kit"><a href="#core-of-NVIDIA™-JETSON-NANO™-development-kit" class="headerlink" title="core of NVIDIA™ JETSON NANO™ development kit"></a>core of NVIDIA™ JETSON NANO™ development kit</h4><h4 id="ultra-sound-sensor-infrared-sensor-camera"><a href="#ultra-sound-sensor-infrared-sensor-camera" class="headerlink" title="ultra sound sensor, infrared sensor, camera"></a>ultra sound sensor, infrared sensor, camera</h4><h2 id="Core-technology"><a href="#Core-technology" class="headerlink" title="Core technology"></a>Core technology</h2><ul><li>Lane detection by visual</li></ul><ol><li>Image correction</li><li>Image masking</li><li>Detection and draw<br><img src="http://r.photo.store.qq.com/psc?/V52O6T4v1BaKX82y9mu62U2PpX2MjRTM/45NBuzDIW489QBoVep5mcWhCWlT2mPqcJ06TOOEZS9GD8YsmeXqI0lGx9.n4DmOCeS3by.au5ySrywtiTc198U2NP0HWgVO7gUCWSobmIU4!/r" alt="Lane dection"><iframe width="800" height="600" src="https://www.youtube.com/embed/rnZj9ERG7J8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><iframe src="//player.bilibili.com/player.html?aid=890260479&bvid=BV1pP4y1a7Lm&cid=403883060&page=1" width="800px" height="600px" border="0" frameborder="yes" framespacing="0" allowfullscreen="true"> </iframe></li></ol><ul><li>Object detection by visual using YOLOV4</li><li>Distance detection<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__ultra_detection</span>(<span class="params">self</span>):</span></span><br><span class="line">    gpio.output(channels=self.__trig_pin, values=gpio.HIGH)</span><br><span class="line">    time.sleep(<span class="number">0.000015</span>)</span><br><span class="line">    gpio.output(channels=self.__trig_pin, values=gpio.LOW)</span><br><span class="line">    </span><br><span class="line">    tic = time.time()</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> gpio.<span class="built_in">input</span>(self.__echo_pin):</span><br><span class="line">        <span class="keyword">if</span> time.time() - tic &gt; self.__timeout:</span><br><span class="line">           <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">    tic = time.time()</span><br><span class="line">    <span class="keyword">while</span> gpio.<span class="built_in">input</span>(self.__echo_pin):</span><br><span class="line">        <span class="keyword">if</span> time.time() - tic &gt; self.__timeout:</span><br><span class="line">           <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">    toc = time.time()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (toc - tic) * <span class="number">340</span> / <span class="number">2</span></span><br></pre></td></tr></table></figure></li><li>Multi threading<table><thead><tr><th>线程1</th><th>线程2</th><th>线程3</th></tr></thead><tbody><tr><td>内容</td><td>内容</td><td>内容</td></tr><tr><td>内容</td><td>内容</td><td>内容</td></tr><tr><td>内容</td><td>内容</td><td>内容</td></tr></tbody></table><blockquote><p>Blog 基础功能语法测试</p><p><a href="https://blog.csdn.net/weixin_45366499/article/details/106558047">安装文章</a></p><p><a href="https://www.cnblogs.com/whiremapple/p/12419113.html#/c/subject/p/12419113.html">基础功能</a></p><p><a href="https://blog.csdn.net/u014061630/article/details/81359144">图文详解</a></p><p><a href="https://sunhwee.gitee.io/posts/7e1e06e9.html">视频插入</a></p><p><a href="https://butterfly.js.org/">Butterfly网页开发设置</a></p></blockquote></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;to simulate FSD of Tesla at ho</summary>
      
    
    
    
    <category term="FSD" scheme="http://example.com/categories/FSD/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="FSD" scheme="http://example.com/tags/FSD/"/>
    
  </entry>
  
</feed>
